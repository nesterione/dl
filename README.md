# Краткое содержание курса по Deep Learning 

Репозиторий для отправки заданий [https://github.com/nesterione/dl-exercises](https://github.com/nesterione/dl-exercises)

В рамках данного курса будут рассмотрены основы машинного обучения и искусственных нейронных сетей. Курс рассчитан на людей, имеющих базовые навыки программирования на любом языке и не имеющих глубоких знаний линейной алгебры. Несколько первых занятий будут посвящены изучению языка программирования Python и математики, необходимой для понимания принципов работы алгоритмов. Полный цикл занятий охватывает почти все основные разделы машинного обучения, а также подводит к пониманию концепции Deep Learning. После каждого занятия будет выдаваться практическое задание для лучшего закрепления пройденного материала. 


## Вводное занятие:

Ознакомительная лекция, в ходе которой слушатели узнают о  правилах проведения курса, понятии искусственного интеллекта и сферах его применения. Участники смогут поближе познакомиться с авторами и задать интересующие их вопросы.

## 1: Python Basics:

Установка, настройка рабочего окружения. Средства разработки. Jupyter Notebook. Основные конструкции языка. 

## 2. Матрицы и тензоры

Занятие посвящено основам линейной алгебры, как неотъемлемой части машинного обучения. Понятие матрицы и тензора. Матричная арифметика и тензорное исчисление. Как запрограммировать операции с матрицами.

## 3. Numpy. Работа с матрицами. Векторизация.

Модуль numerical python (Numpy) для работы с матрицами. Векторизация вместо циклов. Индексация и срезы в массивах. Чтение и запись файлов с помощью Numpy.

## 4. Линейная регрессия и градиентный спуск

- задача регрессии
- линейная регрессия
- многомерная оптимизация, градиентный спуск
- частная производная
- алгоритм градиентного спуска
- нормализация данных

## 5. Полиномиальная и логистическая регрессия.

- Повторение 
- Полиномиальная регрессия 
- Недообучение и переобучение. Регуляризация.
- Задача классификации. Логистическая регрессия.
- Основы оценки качества модели. 
- Работа с категориальными признаками.

## 6. Машины опорных векторов. Обучение без учителя

- Машины опорных векторов (SVM) 
- Обучение без учителя. K-means 

## 7. Решающие деревья. Градиентный бустинг. Оценка модели

- Повторение
- Алгоритмы основанные на решающих деревьях
- Ансамбли алгоритмов. Случайный лес. Градиентный бустинг
- Метрики оценки моделей

## 8. Attention! Персептрон!

Идея возникновения искусственных нейронных сетей, нейрон МакКалока-Питса. Однослойный персептрон. Кросс-энтропия и алгоритм обратного распространения ошибки.

## 9. Нейронные сети. Продолжение. Начало работы с Keras

- Установка keras и tensorflow 
- Использование keras для создания нейронных сетей
- Минибатч градиентный спуск 
- Стохастический градиентный спуск с минибатчем
- Softmax активация и кросс-энтропия с softmax
- Онлайн обучение
- Регуляризация

## 10. Введение в Deep Learning. "Копаем глубже"

- Предпосылки. 
- Проблемы глубоких сетей.
- Предобучение, ограниченные машины Больцмана.
- Нормализованная инициализация весов.
- ReLU активация.
- Проклятье размерности.
- Dropout регуляризация.

## 11. Введение в CNN. Учим нейронные сети видеть

- Идея свёрточных нейронных сетей
- Constitutional  layer, polling layer
- Обзор архитектур свёрточных сетей
- Transfer learning

## 12. Автоэнкодеры. Сжать, шум подавить и сгенерировать

- Проклятие размерности
- Отбор признаков, снижение размерности
- Автоэнкодер
- Разреженный автоэнкодер
- Шумоподавляющий автоэнкодер
- Вариационный автоэнкодер
- Автоэнкодер с условием (conditional)

## 13. Курсовой проект 

Консультация по выбору и реализации последнего задания курса.
